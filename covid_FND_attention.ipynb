{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilfg7i6tWPEJ",
        "outputId": "6d98e522-abda-4c4c-c055-016173dcf636"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWHqPSGrgK4D",
        "outputId": "bbeef5b3-56cd-433e-b22c-9dc7fe3fdce3"
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/NLP_Monsoon2020/Midsem_task1/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/NLP_Monsoon2020/Midsem_task1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPsakRLuhLdS",
        "outputId": "d8ece841-00ba-4ddf-c38f-eb29f0d152f6"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \u001b[0m\u001b[01;34massets\u001b[0m/\n",
            " bert\n",
            " bert-model\n",
            " \u001b[01;34mcache_dir\u001b[0m/\n",
            "'Constraint@AAAI2021 - COVID19 Fake News Detection in English results.csv'\n",
            "'Constraint_English_Test - Sheet1.csv'\n",
            "'Constraint_English_Train _Comma.csv'\n",
            "'Constraint_English_Train _Comma.gsheet'\n",
            " Constraint_English_Train.xlsx\n",
            " Constraint_English_Val_Comma.csv\n",
            " Constraint_English_Val.xlsx\n",
            " model1.pb\n",
            " nlp_midsem_attention.ipynb\n",
            " nlp_midsem_task1_main.ipynb\n",
            " \u001b[01;34moutputs\u001b[0m/\n",
            " \u001b[01;34mruns\u001b[0m/\n",
            " \u001b[01;34mvariables\u001b[0m/\n",
            " \u001b[01;34mwandb\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D15InJAehObz"
      },
      "source": [
        "import json\n",
        "import re\n",
        "import csv\n",
        "import nltk\n",
        "import math\n",
        "# import gensim = 3.8.3\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.util import ngrams\n",
        "# from num2words import num2words\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy6pxtWV52He"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgSzF6rlsZ6t",
        "outputId": "1736ff2f-f85b-4c95-c002-5a859457f01a"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmFSVDTchOef",
        "outputId": "ba0e959c-2c53-44e9-a2e9-365eaa8a5106"
      },
      "source": [
        "train_data_df = pd.read_csv('Constraint_English_Train _Comma.csv', index_col=0, header=0)\n",
        "val_data_df = pd.read_csv('Constraint_English_Val_Comma.csv', index_col=0, header=0)\n",
        "\n",
        "train_data_df.replace(to_replace=['fake', 'real'], value=[1, 0], inplace=True)\n",
        "print(train_data_df['label'].value_counts())\n",
        "\n",
        "val_data_df.replace(to_replace=['fake','real'], value=[1,0],inplace=True)\n",
        "print(val_data_df['label'].value_counts())\n",
        "\n",
        "test_data_df = pd.read_csv('Constraint_English_Test - Sheet1.csv')\n",
        "\n",
        "# x_train = train_data['tweet']\n",
        "# y_train = train_data['label']\n",
        "\n",
        "# x_val = val_data['tweet']\n",
        "# y_val = val_data['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    3360\n",
            "1    3060\n",
            "Name: label, dtype: int64\n",
            "0    1120\n",
            "1    1020\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rxajeOA4kQ3",
        "outputId": "6d6a62d0-d09b-4e82-aae2-4a0659d4e3fd"
      },
      "source": [
        "print(train_data_df.head())\n",
        "print(val_data_df.head())\n",
        "print(test_data_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                tweet  label\n",
            "id                                                          \n",
            "1   The CDC currently reports 99031 deaths. In gen...      0\n",
            "2   States reported 1121 deaths a small rise from ...      0\n",
            "3   Politically Correct Woman (Almost) Uses Pandem...      1\n",
            "4   #IndiaFightsCorona: We have 1524 #COVID testin...      0\n",
            "5   Populous states can generate large case counts...      0\n",
            "                                                tweet  label\n",
            "id                                                          \n",
            "1   Chinese converting to Islam after realising th...      1\n",
            "2   11 out of 13 people (from the Diamond Princess...      1\n",
            "3   COVID-19 Is Caused By A Bacterium, Not Virus A...      1\n",
            "4   Mike Pence in RNC speech praises Donald Trump’...      1\n",
            "5   6/10 Sky's @EdConwaySky explains the latest #C...      0\n",
            "   id                                              tweet\n",
            "0   1  Our daily update is published. States reported...\n",
            "1   2             Alfalfa is the only cure for COVID-19.\n",
            "2   3  President Trump Asked What He Would Do If He W...\n",
            "3   4  States reported 630 deaths. We are still seein...\n",
            "4   5  This is the sixth time a global health emergen...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLfazoK8lpm3"
      },
      "source": [
        "train_data = train_data_df.to_numpy()\n",
        "val_data = val_data_df.to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsklkBk8GMWh"
      },
      "source": [
        "\n",
        "test_data = test_data_df['tweet'].to_numpy()\n",
        "for i in range(len(test_data)):\n",
        "  test_data[i] = [test_data[i]]\n",
        "\n",
        "test_data = np.array(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXlMUqCq97C7",
        "outputId": "63c44be4-0998-49a9-a78d-f1c6853f402a"
      },
      "source": [
        "print(train_data.shape)\n",
        "print(train_data[1595])\n",
        "print(test_data.shape)\n",
        "print(test_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6420, 2)\n",
            "['https://t.co/HcGWx8897G California fires, camel racing, coronavirus tribute; The World in Photos, Sept. 28 https://t.co/vmEP0HhNbC https://t.co/4KvZ8FEWPX'\n",
            " 1]\n",
            "(2140,)\n",
            "['Our daily update is published. States reported 734k tests 39k new cases and 532 deaths. Current hospitalizations fell below 30k for the first time since June 22. https://t.co/wzSYMe0Sht']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtfWWarnAPkb",
        "outputId": "9203d9dc-08d6-489e-82a2-fee8ff95eead"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxNml-P_AXdw"
      },
      "source": [
        "import emoji\n",
        "def clean_text(text):\n",
        "  # print(text)\n",
        "  text = re.sub(r'#','', text)\n",
        "  # Remove HTML special entities (e.g. &amp;)\n",
        "  # print(text)\n",
        "  text = re.sub(r'\\&\\w*;', '', text)\n",
        "  # Remove tickers\n",
        "  # text = re.sub(r'\\$\\w*', '', text)\n",
        "  # Remove hyperlinks\n",
        "  # print(text)\n",
        "  # print('hello')\n",
        "  # text = re.sub(r'https?:\\/\\/.*\\/*', '', text)\n",
        "  # Remove whitespace (including new line characters)\n",
        "  # print(text)\n",
        "  # print(text)\n",
        "  # print('hello')\n",
        "  text = re.sub(r'\\s\\s+','', text)\n",
        "  text = re.sub(r'[ ]{2, }',' ',text)\n",
        "  # Remove URL, RT, mention(@)\n",
        "  # print(text)\n",
        "  # print(text)\n",
        "  # print('hello')\n",
        "  text=  re.sub(r'http(\\S)+', '',text)\n",
        "  text=  re.sub(r'http ...', '',text)\n",
        "  text=  re.sub(r'(RT|rt)[ ]*@[ ]*[\\S]+','',text)\n",
        "  text=  re.sub(r'RT[ ]?@','',text)\n",
        "  text = re.sub(r'@[\\S]+','',text)\n",
        "  text = re.sub(r'[^\\w\\s]', '', text) \n",
        "  # print(text)\n",
        "  text = re.sub('\\\\n', ' ',text)\n",
        "  text = re.sub('\\\\r', ' ',text)\n",
        "  text = re.sub('\\\\t', ' ',text)\n",
        "  text = re.sub('<[^>]*>', ' ',text)\n",
        "\n",
        "  # Remove emoji's\n",
        "  text = emoji.demojize(text)\n",
        "  text = text.replace(\":\",\" \")\n",
        "  text = ' '.join(text.split()) \n",
        "  text = re.sub(\"([^\\x00-\\x7F])+\",\" \",text)\n",
        "  \n",
        "  return text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return [lemmatizer.lemmatize(w) for w in text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "169DPqzkAlbV",
        "outputId": "a20ff036-3fbf-4892-9cda-0efcb15fd21c"
      },
      "source": [
        "print(train_data[1595])\n",
        "print(clean_text(train_data[1595][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['https://t.co/HcGWx8897G California fires, camel racing, coronavirus tribute; The World in Photos, Sept. 28 https://t.co/vmEP0HhNbC https://t.co/4KvZ8FEWPX'\n",
            " 1]\n",
            "California fires camel racing coronavirus tribute The World in Photos Sept 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJD4xKZdBZK3"
      },
      "source": [
        "def parser(data):\n",
        "  for i in range(len(data)):\n",
        "    data[i][0] = clean_text(data[i][0])\n",
        "    if(data[i][0]==''):\n",
        "      print(i)\n",
        "    tokens  = word_tokenize(data[i][0])\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    data[i][0] = [lemmatizer.lemmatize(w) for w in tokens]\n",
        "    # print(data[i][0])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUhip8twE0Yy"
      },
      "source": [
        "parser(train_data)\n",
        "parser(val_data)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHRB4uxbeZcF"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EinwHkBxGqIo"
      },
      "source": [
        "parser(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CstDUbRvFCIA",
        "outputId": "f8817adb-a9b8-4303-90e2-b19163230cf5"
      },
      "source": [
        "print(train_data[0][0])\n",
        "print(val_data[0][0])\n",
        "print(test_data[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'CDC', 'currently', 'report', '99031', 'death', 'In', 'general', 'the', 'discrepancy', 'in', 'death', 'count', 'between', 'different', 'source', 'are', 'small', 'and', 'explicable', 'The', 'death', 'toll', 'stand', 'at', 'roughly', '100000', 'people', 'today']\n",
            "['Chinese', 'converting', 'to', 'Islam', 'after', 'realising', 'that', 'no', 'muslim', 'wa', 'affected', 'by', 'Coronavirus', 'COVD19', 'in', 'the', 'country']\n",
            "['Our', 'daily', 'update', 'is', 'published', 'States', 'reported', '734k', 'test', '39k', 'new', 'case', 'and', '532', 'death', 'Current', 'hospitalization', 'fell', 'below', '30k', 'for', 'the', 'first', 'time', 'since', 'June', '22']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58L_szlmq-WX",
        "outputId": "7a8a9403-613a-48d3-d1a7-bcbdd697b8c4"
      },
      "source": [
        "vocab = set()\n",
        "\n",
        "def create_vocab(vocab_set, data):\n",
        "  for sample in data:\n",
        "    for token in sample[0]:\n",
        "      if(token not in vocab_set):\n",
        "        vocab_set.add(token)\n",
        "  print(len(vocab_set))\n",
        "\n",
        "create_vocab(vocab,train_data)\n",
        "create_vocab(vocab,val_data)\n",
        "create_vocab(vocab,test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17713\n",
            "20633\n",
            "23208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vB-Jnxcl3yY",
        "outputId": "ab842036-cda9-476a-d8d3-9921ac8cc87c"
      },
      "source": [
        "glove_dict = {}\n",
        "\n",
        "def create_glove_dict(gdict, data):\n",
        "  f = open(\"/content/drive/My Drive/NLP_project/atten/glove.840B.300d.txt\",'r',encoding='utf-8')\n",
        "  i = 0\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    if(word in vocab):\n",
        "      st = 1\n",
        "      if(len(values)>301):\n",
        "        st+=len(values) - 301\n",
        "      vector = np.asarray(values[st:],'float32')\n",
        "      gdict[word] = vector\n",
        "\n",
        "create_glove_dict(glove_dict,train_data)\n",
        "create_glove_dict(glove_dict,val_data)\n",
        "create_glove_dict(glove_dict,test_data)\n",
        "\n",
        "# with open(\"glove.840B.300d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "#   i=0\n",
        "#   for line in f:\n",
        "#     i+=1\n",
        "#     values = line.split()\n",
        "#     word = values[0]\n",
        "#     if(word in vocab):\n",
        "#       st = 1\n",
        "#       if(len(values)>301):\n",
        "#         st+= len(values) - 301\n",
        "#       vector = np.asarray(values[st:],'float32')\n",
        "#       glove_dict[word] = vector\n",
        "\n",
        "print(len(glove_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhFff9bHy8hf"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwwPsPqvxMXA"
      },
      "source": [
        "with open('glove_dict_file','wb') as f:\n",
        "  pickle.dump(glove_dict,f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0deu1jQxMe0"
      },
      "source": [
        "with open('glove_dict_file','rb') as f:\n",
        "  glove_dict = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBxSvP-zxxY5",
        "outputId": "880b2f15-aa31-4cf3-8102-0c8a2d57afa9"
      },
      "source": [
        "print(len(glove_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY_TluWv5r3s",
        "outputId": "79d0da8b-b0d2-4e96-b1a0-fc4098c190fa"
      },
      "source": [
        "# mu, sigma = 0, 0.1\n",
        "# s = np.random.normal(mu, sigma, 300)\n",
        "# s = np.asarray(s,'float32')\n",
        "s = [0.0]*300\n",
        "# print(s.shape)\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOp-Z-ppPIDS",
        "outputId": "b531a7e8-033a-4c62-bb05-9748e6760fd9"
      },
      "source": [
        "print(type(s[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'float'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW7uOyreoEzL",
        "outputId": "33abc1f6-b972-42d1-eea7-ddc278ccbabf"
      },
      "source": [
        "for word in vocab:\n",
        "  if(word not in glove_dict):\n",
        "    glove_dict[word] = np.asarray(s,'float32')\n",
        "\n",
        "print(len(vocab))\n",
        "print(len(glove_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23208\n",
            "23208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfpYMcpTt61q",
        "outputId": "740e580a-e49c-4f85-a373-29a7fc88bdc8"
      },
      "source": [
        "!pip install texttable\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting texttable\n",
            "  Downloading https://files.pythonhosted.org/packages/06/f5/46201c428aebe0eecfa83df66bf3e6caa29659dbac5a56ddfd83cae0d4a4/texttable-1.6.3-py2.py3-none-any.whl\n",
            "Installing collected packages: texttable\n",
            "Successfully installed texttable-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VOsT4BtuK2z",
        "outputId": "ec9ad3e6-11d9-49d7-ff46-136a32ecc41e"
      },
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter==latest+{CUDA}     -f https://pytorch-geometric.com/whl/torch-{TORCH}.html\n",
        "!pip install torch-sparse==latest+{CUDA}      -f https://pytorch-geometric.com/whl/torch-{TORCH}.html\n",
        "!pip install torch-cluster==latest+{CUDA}     -f https://pytorch-geometric.com/whl/torch-{TORCH}.html\n",
        "!pip install torch-spline-conv==latest+{CUDA} -f https://pytorch-geometric.com/whl/torch-{TORCH}.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 663kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 598kB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5c/3e95b76321fb14f24cc2ace392075717f645c4632e796ee0db1bc7d17231/torch_geometric-1.6.3.tar.gz (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.14)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.4)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (50.3.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.3-cp36-none-any.whl size=322720 sha256=99be4c812dc89e9f2ab29b3ec547d70e8c2bb72d08da7f9bfd33fd0aa8b0aa27\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/47/1e/0af8ce3e21783c3e584c22502011a3367c091694eebc50a971\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72TOtiQmzz04"
      },
      "source": [
        "# import torch\n",
        "\n",
        "class AttentionModule(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, args):\n",
        "        \n",
        "        super(AttentionModule, self).__init__()\n",
        "        self.args = args\n",
        "        self.filters_3 = 300\n",
        "        self.filters_4 = 64\n",
        "        self.setup_weights()\n",
        "        self.init_parameters()\n",
        "\n",
        "    def setup_weights(self):\n",
        "        \n",
        "        self.weight_matrix = torch.nn.Parameter(torch.Tensor(self.filters_3,\n",
        "                                                             self.filters_3))\n",
        "\n",
        "    def init_parameters(self):\n",
        "       \n",
        "        torch.nn.init.xavier_uniform_(self.weight_matrix)\n",
        "\n",
        "    def forward(self, embedding):\n",
        "        # print(type(embedding))\n",
        "        global_context = torch.mean(torch.matmul(embedding, self.weight_matrix), dim=0)\n",
        "        transformed_global = torch.tanh(global_context)\n",
        "        # print(type(transformed_global))\n",
        "        # print(transformed_global.shape)\n",
        "        sigmoid_scores = torch.sigmoid(torch.mm(embedding, transformed_global.view(-1, 1)))\n",
        "        representation = torch.mm(torch.t(embedding), sigmoid_scores)\n",
        "        return representation\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Jr4dmBXo6qM"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        \n",
        "        super(Model, self).__init__()\n",
        "        self.args = args\n",
        "        self.tensor_neurons = 16\n",
        "        self.bins = 16\n",
        "        self.histogram = False\n",
        "        self.setup_layers()\n",
        "\n",
        "    def setup_layers(self):\n",
        "        \n",
        "        \n",
        "        self.attention = AttentionModule(self.args)\n",
        "      \n",
        "        \n",
        "        self.fully_connected_first = torch.nn.Linear(300,200)\n",
        "\n",
        "       \n",
        "\n",
        "        self.fully_connected_second = torch.nn.Linear(200,100)\n",
        "        self.fully_connected_third = torch.nn.Linear(100,50)\n",
        "        \n",
        "        self.fully_connected_fourth = torch.nn.Linear(50,25)\n",
        "        # self.fully_connected_fifth = torch.nn.Linear(16,8)\n",
        "        self.scoring_layer = torch.nn.Linear(25,1)\n",
        "\n",
        "  \n",
        "\n",
        "    def forward(self, data):\n",
        "        \n",
        "        utter_feature = torch.from_numpy(np.array(data[0]))\n",
        "        utter_atten = self.attention(utter_feature)\n",
        "        scores = utter_atten\n",
        "        scores = torch.t(scores)\n",
        "        # print(scores.shape)\n",
        "\n",
        "        score1 = torch.nn.functional.relu(self.fully_connected_first(scores))\n",
        "        score2 = torch.nn.functional.relu(self.fully_connected_second(score1))\n",
        "        score3 = torch.nn.functional.relu(self.fully_connected_third(score2))\n",
        "        score4 = torch.nn.functional.relu(self.fully_connected_fourth(score3))\n",
        "        # score5 = torch.nn.functional.relu(self.fully_connected_fifth(score4))\n",
        "        score = torch.sigmoid(self.scoring_layer(score4))\n",
        "        \n",
        "        return score,score4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJsLLMywxLR3"
      },
      "source": [
        "class Trainer(object):\n",
        "    \n",
        "    def __init__(self, args,train_data,val_data,test_data,glove_dict):\n",
        "        \n",
        "        self.args = args\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "        self.glove_dict = glove_dict\n",
        "        self.embedding_gen()\n",
        "        self.setup_model()\n",
        " \n",
        "    def setup_model(self):\n",
        "        \n",
        "        self.model = Model(self.args)\n",
        " \n",
        "    def embedding_gen(self):\n",
        "\n",
        "      print(\"\\nGenerating for train\\n\")\n",
        "      label_train_data = []\n",
        "      for sample in self.train_data[:,1]:\n",
        "        label = sample\n",
        "        label_train_data.append(label)\n",
        "      label_train_data = np.array(label_train_data)\n",
        "\n",
        "      tweet_train_data = []\n",
        "      for sample in self.train_data[:,0]:\n",
        "        feature_vec = []\n",
        "        if(len(sample)<=1):\n",
        "          print(sample)\n",
        "        for token in sample:\n",
        "          feature_vec.append(self.glove_dict[token])\n",
        "        tweet_train_data.append(np.array(feature_vec))\n",
        "      tweet_train_data = np.array(tweet_train_data)\n",
        "\n",
        "\n",
        "      print(\"\\nGenerating for val\\n\")\n",
        "\n",
        "      label_val_data = []\n",
        "      for sample in self.val_data[:,1]:\n",
        "        label = sample\n",
        "        label_val_data.append(label)\n",
        "      label_val_data = np.array(label_val_data)\n",
        "\n",
        "      tweet_val_data = []\n",
        "      for sample in self.val_data[:,0]:\n",
        "        feature_vec = []\n",
        "        for token in sample:\n",
        "          feature_vec.append(self.glove_dict[token])\n",
        "        tweet_val_data.append(np.array(feature_vec))\n",
        "      tweet_val_data = np.array(tweet_val_data)\n",
        "\n",
        "  \n",
        "\n",
        "      print(\"\\nGenerating for test\\n\")\n",
        "\n",
        "      tweet_test_data = []\n",
        "      for sample in self.val_data[:,0]:\n",
        "        feature_vec = []\n",
        "        for token in sample:\n",
        "          feature_vec.append(self.glove_dict[token])\n",
        "        tweet_test_data.append(np.array(feature_vec))\n",
        "      tweet_test_data = np.array(tweet_test_data)\n",
        "\n",
        "      self.train_dataset = []\n",
        "      self.val_dataset = []\n",
        "      self.test_dataset = []\n",
        "      \n",
        "      for i in range(len(self.train_data)):\n",
        "        self.train_dataset.append([tweet_train_data[i],label_train_data[i]])\n",
        "      for i in range(len(self.val_data)):\n",
        "        self.val_dataset.append([tweet_val_data[i],label_val_data[i]])\n",
        "      for i in range(len(self.test_data)):\n",
        "        self.test_dataset.append([tweet_test_data[i]])\n",
        "      \n",
        "      self.train_dataset = np.array(self.train_dataset)\n",
        "      self.val_dataset = np.array(self.val_dataset)\n",
        "      self.test_dataset = np.array(self.test_dataset)\n",
        "\n",
        "      print(self.train_dataset.shape)\n",
        "      print(self.val_dataset.shape)\n",
        "      print(self.test_dataset.shape)\n",
        " \n",
        "            \n",
        "    def create_batches(self):\n",
        "       \n",
        "        \n",
        "        mod_batches = []\n",
        "        np.random.shuffle(self.train_dataset)\n",
        "        \n",
        "        ind = 0\n",
        "        while(ind<len(self.train_dataset)):  \n",
        "          batches = []\n",
        "          for num in range(10):\n",
        "            batches.append(self.train_dataset[ind])\n",
        "            ind += 1\n",
        "           \n",
        "          mod_batches.append(batches)\n",
        "        return mod_batches\n",
        " \n",
        "    def process_batch(self, batch):\n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        losses = 0\n",
        "        # print('process_batch')\n",
        "        # it = 0\n",
        "        for sample in batch:\n",
        "            data = sample[:len(sample)-1]\n",
        "            label = sample[-1]\n",
        "            result = torch.from_numpy(np.array(label).reshape(1,1)).view(-1).float() \n",
        "            prediction,_ = self.model(data)\n",
        "            losses = losses + torch.nn.functional.mse_loss(result, prediction)\n",
        "        losses.backward(retain_graph=True)\n",
        "        self.optimizer.step()\n",
        "        loss = losses.item()\n",
        "        return loss\n",
        " \n",
        "    def fit(self):\n",
        "      \n",
        " \n",
        "        print(\"\\nModel training.\\n\")\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(),\n",
        "                                          lr=0.001,\n",
        "                                          weight_decay=5*10**-4)\n",
        " \n",
        "        self.model.train()\n",
        "        \n",
        "        epochs = 150\n",
        "        min_loss = 10000\n",
        "        min_loss_epoch = 0\n",
        "        self.min_loss_model = self.model\n",
        "        for epoch in range(epochs):\n",
        " \n",
        "            batches = self.create_batches()\n",
        "            \n",
        "            self.loss_sum = 0\n",
        "            main_index = 0\n",
        "\n",
        "            for batch in batches:\n",
        "                loss_score = self.process_batch(batch)\n",
        "                \n",
        "                main_index = main_index + len(batch)\n",
        "                # print(main_index)\n",
        "                self.loss_sum = self.loss_sum + loss_score * len(batch)\n",
        "                # self.loss_sum = self.loss_sum + loss_score\n",
        "                loss = self.loss_sum/main_index\n",
        "                \n",
        "                \n",
        "            # print(loss)\n",
        "            if loss < min_loss:\n",
        "                    min_loss = loss\n",
        "                    min_loss_epoch = epoch\n",
        "                    self.min_loss_model = self.model\n",
        "                    print('min_loss: ',min_loss)\n",
        "                    print(min_loss_epoch)\n",
        "                    # print(self.min_loss_model)\n",
        "            \n",
        " \n",
        "        svm_feature = []      \n",
        "        for sample in self.train_dataset:\n",
        "          data = sample[:len(sample)-1]\n",
        "          _,feature = self.min_loss_model(data)\n",
        "          svm_feature.append(feature.tolist()[0])\n",
        " \n",
        "        svm_target = []\n",
        "        for sample in self.train_dataset:\n",
        "          result = sample[-1]\n",
        "          svm_target.append(result)\n",
        "\n",
        "\n",
        "        cnt0 = 0\n",
        "        cnt1 = 0\n",
        "        for i in svm_target:\n",
        "          if(i==0):\n",
        "            cnt0+=1\n",
        "          else:\n",
        "            cnt1+=1\n",
        "        print(cnt0)\n",
        "        print(cnt1)\n",
        " \n",
        "        \n",
        "        X = np.array(svm_feature)\n",
        "        y = np.array(svm_target)\n",
        "        print(y.shape)\n",
        "        print(np.unique(y))\n",
        "        from sklearn import svm\n",
        "        from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "        self.svm_rbf_model = svm.SVC(kernel = 'rbf',gamma = 'scale', decision_function_shape = 'ovr')\n",
        "        self.svm_rbf_model.fit(X,y)\n",
        "        print(\"svm_model_trained\")\n",
        "        #now adding SVM rbf classifier for removing step function\n",
        "        \n",
        "    \n",
        " \n",
        "    \n",
        "    def score(self):\n",
        "        \n",
        "        print(\"\\n\\nModel evaluation.\\n\")\n",
        "        \n",
        " \n",
        "        model1 = self.min_loss_model\n",
        "        model1.eval()\n",
        "        self.scores = []\n",
        " \n",
        "        predictions = []\n",
        "        true_label = []\n",
        "        for sample in self.val_dataset:\n",
        "            \n",
        "            data = sample[:len(sample)-1]\n",
        "            true_label.append(sample[-1])\n",
        "            _,prediction = model1(data)\n",
        "            predict = self.svm_rbf_model.predict(np.array(prediction.tolist())) \n",
        "            predictions.append(predict)\n",
        "        \n",
        "        return true_label,predictions,model1,self.svm_rbf_model\n",
        " \n",
        "       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-g_CRJQxLWd",
        "outputId": "e21c4f26-7528-4da8-a35e-758765b7a497"
      },
      "source": [
        "# print(type(data))\n",
        "args = 'ut-sp-ct-cp-sh'\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm, trange\n",
        "import pickle\n",
        "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "# kf = KFold(n_splits=5)\n",
        "# kf.get_n_splits(data)\n",
        "results = []\n",
        "accur = []\n",
        "# print(type(df))\n",
        "max_f1 = 0\n",
        "# for train_index, test_index in skf.split(data,df['sarcasm'].to_numpy()):\n",
        "# for train_index, test_index in kf.split(data):  \n",
        "  # train_data, test_data = data[train_index], data[test_index]\n",
        "  # print(train_data.shape)\n",
        "  # print(test_data.shape)\n",
        "\n",
        "trainer = Trainer(args,train_data,val_data,test_data,glove_dict)\n",
        "trainer.fit()\n",
        "y_test,y_pred,atten_model,svm_model = (trainer.score())\n",
        "  # filename_atten = args+'_atten_model_50.sav'\n",
        "  # filename_svm = args+'_svm_model_50.sav'\n",
        "  # filename_atten = args+'_atten_model_75.sav'\n",
        "  # filename_svm = args+'_svm_model_75.sav'\n",
        "  # filename_atten = args+'_atten_model_100.sav'\n",
        "  # filename_svm = args+'_svm_model_100.sav'\n",
        "\n",
        "  # filename_atten = args+'_atten_model_150.sav'\n",
        "  # filename_svm = args+'_svm_model_150.sav'\n",
        "accur.append(accuracy_score(y_test, y_pred))\n",
        "results.append(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
        "\n",
        "  # if(max_f1 < results[-1][2]):\n",
        "  #   max_f1 = results[-1][2]\n",
        "  #   pickle.dump(atten_model, open(filename_atten, 'wb'))\n",
        "  #   pickle.dump(svm_model,open(filename_svm,'wb'))\n",
        "  \n",
        "print(accur[-1])\n",
        "print(classification_report(y_test, y_pred))\n",
        "  \n",
        "\n",
        "# avg = [0,0,0,0]\n",
        "# for i in range(5):\n",
        "#     x, y, z, _ = results[i]\n",
        "#     avg[0] += x\n",
        "#     avg[1] += y\n",
        "#     avg[2] += z\n",
        "#     avg[3] += accur[i]\n",
        "# avg[0]/=5\n",
        "# avg[1]/=5\n",
        "# avg[2]/=5\n",
        "# avg[3]/=5\n",
        "\n",
        "\n",
        "# print(f\"Avg Accuracy: {avg[3]:.3f}\")\n",
        "# print(f\"Avg weighted precision: {avg[0]:.3f} :: Avg weighted recall: {avg[1]:.3f} :: Avg weighted F1: {avg[2]:.3f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Generating for train\n",
            "\n",
            "['StopTheSpreadOfCoronaLockdown21Corona']\n",
            "\n",
            "Generating for val\n",
            "\n",
            "\n",
            "Generating for test\n",
            "\n",
            "(6420, 2)\n",
            "(2140, 2)\n",
            "(2140, 1)\n",
            "\n",
            "Model training.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "min_loss:  0.963976062072758\n",
            "0\n",
            "min_loss:  0.5734441211013214\n",
            "1\n",
            "min_loss:  0.43563952836030717\n",
            "2\n",
            "min_loss:  0.3588319336181304\n",
            "3\n",
            "min_loss:  0.2926749471938529\n",
            "4\n",
            "min_loss:  0.2457936442664212\n",
            "5\n",
            "min_loss:  0.23815690890326555\n",
            "6\n",
            "min_loss:  0.23061507180987512\n",
            "7\n",
            "min_loss:  0.21113455520771093\n",
            "9\n",
            "min_loss:  0.17505056217002063\n",
            "10\n",
            "min_loss:  0.1604042697115695\n",
            "12\n",
            "min_loss:  0.13681281380948185\n",
            "14\n",
            "min_loss:  0.11711085412185743\n",
            "17\n",
            "min_loss:  0.11335211210957988\n",
            "21\n",
            "min_loss:  0.09302018147823529\n",
            "27\n",
            "min_loss:  0.0759657920951073\n",
            "43\n",
            "min_loss:  0.06685988406237085\n",
            "53\n",
            "min_loss:  0.061526685086909144\n",
            "62\n",
            "min_loss:  0.059466756419498855\n",
            "92\n",
            "min_loss:  0.05260729492778089\n",
            "100\n",
            "min_loss:  0.05062330963677242\n",
            "111\n",
            "min_loss:  0.04755152160084596\n",
            "112\n",
            "3360\n",
            "3060\n",
            "(6420,)\n",
            "[0 1]\n",
            "svm_model_trained\n",
            "\n",
            "\n",
            "Model evaluation.\n",
            "\n",
            "0.9065420560747663\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.92      0.91      1120\n",
            "           1       0.91      0.89      0.90      1020\n",
            "\n",
            "    accuracy                           0.91      2140\n",
            "   macro avg       0.91      0.91      0.91      2140\n",
            "weighted avg       0.91      0.91      0.91      2140\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_8hjrTPxLZ0"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcH7zzYrxLUb"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}